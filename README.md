# FabricaModelli ğŸ­

[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/fukuro-kun/FabricaModelli/graphs/commit-activity)
[![Maintenance Mode](https://img.shields.io/badge/Maintenance%20Mode-Passive-yellow.svg)](#)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![CUDA 11.8+](https://img.shields.io/badge/CUDA-11.8%2B-green.svg)](https://developer.nvidia.com/cuda-downloads)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1-red.svg)](https://pytorch.org/)

*Eine Werkstatt fÃ¼r das Training und die Optimierung von KI-Modellen*

> â„¹ï¸ **Aktueller Status**: Dieses Repository befindet sich in der Entwicklung. Derzeit ist das Training eines spezialisierten deutschen Whisper-Modells implementiert. Weitere Modelle und Werkzeuge sind in Planung.

## ğŸ¯ Ãœber das Projekt

FabricaModelli ist eine Sammlung von Tools und Skripten fÃ¼r das Training und die Optimierung verschiedener KI-Modelle. Der Name kommt aus dem Lateinischen und bedeutet "Modell-Werkstatt" - ein Ort, an dem Modelle mit PrÃ¤zision und Sorgfalt "geschmiedet" werden.

### ğŸ™ï¸ Aktueller Fokus: Deutsches Whisper-Modell

Das erste fertiggestellte Werkzeug ist ein spezialisiertes Trainings-Framework fÃ¼r deutsche Spracherkennung basierend auf OpenAI's Whisper. 

**Hauptmerkmale:**
- Training eines deutschen Whisper-Modells mit State-of-the-Art Performance
- Optimiert fÃ¼r Echtzeit-Transkription
- Trainiert auf dem flozi00/asr-german-mixed Dataset (970.064 TrainingssÃ¤tze)
- Ziel-WER (Word Error Rate): 4.77% oder besser
- Multi-GPU Training mit Gradient Checkpointing fÃ¼r effiziente Ressourcennutzung

## ğŸ¤– Implementierte Modelle

### Whisper ğŸ™ï¸
- **Status**: âœ… Trainings-Pipeline implementiert
- **Basis**: Whisper Large V3
- **Datensatz**: flozi00/asr-german-mixed
  - 970.064 TrainingssÃ¤tze
  - 9.799 TestsÃ¤tze
- **Features**:
  - Optimiert fÃ¼r Echtzeit-Transkription
  - Multi-GPU Training Support
  - Gradient Checkpointing
  - FP16 Training
- [ğŸ“š Trainings-Guide](whisper/docs/training.md)
- [ğŸ”§ Konvertierungs-Guide](whisper/docs/conversion.md)

## ğŸ“ Projektstruktur

```
FabricaModelli/
â”œâ”€â”€ whisper/                 # Whisper-spezifische Implementierungen
â”‚   â”œâ”€â”€ train_german_model.py
â”‚   â”œâ”€â”€ convert_model.py
â”‚   â”œâ”€â”€ convert_to_faster.py
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â””â”€â”€ model_config.json
â”‚   â”œâ”€â”€ docs/               # AusfÃ¼hrliche Dokumentation
â”‚   â”‚   â”œâ”€â”€ training.md
â”‚   â”‚   â””â”€â”€ conversion.md
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ shared/                  # Gemeinsam genutzte Funktionen
â”‚   â”œâ”€â”€ logging_utils.py
â”‚   â””â”€â”€ gpu_utils.py
â””â”€â”€ README.md
```

## ğŸ’» System-Anforderungen

### Minimale Anforderungen
- ğŸ® NVIDIA GPU mit 16GB VRAM
- âš¡ CUDA >= 11.8
- ğŸ’¾ 32GB RAM
- ğŸ’¿ 250GB freier Speicherplatz
- ğŸ Python 3.12

### Empfohlene Hardware
- ğŸ® 2x NVIDIA GPU mit je 16GB VRAM
- ğŸ’¾ 64GB RAM
- ğŸ’¿ 500GB freier Speicherplatz (SSD)
- ğŸ’ª 8+ CPU Kerne

## ğŸš€ Installation

### 1. Umgebungsvariablen einrichten

1. Kopieren Sie `.env.template` zu `.env`:
   ```bash
   cp .env.template .env
   ```

2. Passen Sie die Pfade in `.env` an Ihr System an:
   ```bash
   # Beispiel fÃ¼r die .env
   BASE_DIR=/media/ihr_username/pfad/zu/FabricaModelli
   DATA_DIR=${BASE_DIR}/training/data
   MODEL_DIR=${BASE_DIR}/training/models
   LOG_DIR=${BASE_DIR}/training/logs
   CONFIG_DIR=${BASE_DIR}/training/scripts
   ```

Die Umgebungsvariablen werden von allen Skripten verwendet, um die korrekten Pfade zu finden:
- `BASE_DIR`: Hauptverzeichnis des Projekts
- `DATA_DIR`: Speicherort fÃ¼r Trainingsdaten
- `MODEL_DIR`: Speicherort fÃ¼r trainierte Modelle
- `LOG_DIR`: Verzeichnis fÃ¼r Logs
- `CONFIG_DIR`: Verzeichnis fÃ¼r Konfigurationsdateien

### 2. Modellspezifische Installation

Die weitere Installation ist modellspezifisch. Bitte folgen Sie den Anleitungen in der jeweiligen Dokumentation:

- [ğŸ“š Whisper Training Setup](whisper/docs/training.md#1-einrichtung-der-umgebung)
- [ğŸ”§ Whisper Konvertierung Setup](whisper/docs/conversion.md#1-vorbereitung-der-konvertierung)

## âš–ï¸ Lizenz

Dieses Projekt ist unter der [GPL-3.0 Lizenz](LICENSE) lizenziert.

## ğŸ¤ Beitragen

BeitrÃ¤ge sind willkommen! Bitte erstellen Sie einen Issue oder Pull Request. Beachten Sie jedoch den Wartungshinweis am Anfang dieser README.
