# FabricaModelli 

[![Maintenance](https://img.shields.io/badge/Maintained%3F-yes-green.svg)](https://github.com/fukuro-kun/FabricaModelli/graphs/commit-activity)
[![Maintenance Mode](https://img.shields.io/badge/Maintenance%20Mode-Passive-yellow.svg)](#)
[![Python 3.12](https://img.shields.io/badge/python-3.12-blue.svg)](https://www.python.org/downloads/release/python-3120/)
[![CUDA 11.8+](https://img.shields.io/badge/CUDA-11.8%2B-green.svg)](https://developer.nvidia.com/cuda-downloads)
[![License: GPL v3](https://img.shields.io/badge/License-GPLv3-blue.svg)](https://www.gnu.org/licenses/gpl-3.0)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.5.1-red.svg)](https://pytorch.org/)

*Eine Werkstatt f√ºr das Training und die Optimierung von KI-Modellen*

> ‚ÑπÔ∏è **Wartungshinweis**: Dieses Repository wird aus Zeitgr√ºnden passiv gewartet. Issues und Pull Requests werden gelesen, aber Antworten k√∂nnen einige Zeit in Anspruch nehmen. Vielen Dank f√ºr Ihr Verst√§ndnis! Dieses Repository befindet sich ausserdem in der Entwicklung. Derzeit ist das Training eines spezialisierten deutschen Whisper-Modells implementiert. Weitere Modelle und Werkzeuge sind in Planung.

## √úber das Projekt

FabricaModelli ist eine Sammlung von Tools und Skripten f√ºr das Training und die Optimierung verschiedener KI-Modelle. Der Name kommt aus dem Lateinischen und bedeutet "Modell-Werkstatt" - ein Ort, an dem Modelle mit Pr√§zision und Sorgfalt "geschmiedet" werden.

### Aktueller Fokus: Deutsches Whisper-Modell

Das erste fertiggestellte Werkzeug ist ein spezialisiertes Trainings-Framework f√ºr deutsche Spracherkennung basierend auf OpenAI's Whisper. 

**Hauptmerkmale:**
- Training eines deutschen Whisper-Modells mit State-of-the-Art Performance
- Optimiert f√ºr Echtzeit-Transkription
- Trainiert auf dem flozi00/asr-german-mixed Dataset (970.064 Trainingss√§tze)
- Ziel-WER (Word Error Rate): 4.77% oder besser
- Multi-GPU Training mit Gradient Checkpointing f√ºr effiziente Ressourcennutzung

## Implementierte Modelle

### Whisper 
- **Status**: Trainings-Pipeline implementiert
- **Basis**: Whisper Large V3
- **Datensatz**: flozi00/asr-german-mixed
  - 970.064 Trainingss√§tze
  - 9.799 Tests√§tze
- **Features**:
  - Optimiert f√ºr Echtzeit-Transkription
  - Multi-GPU Training Support
  - Gradient Checkpointing
  - FP16 Training
- [ Trainings-Guide](whisper/docs/training.md)
- [ Konvertierungs-Guide](whisper/docs/conversion.md)

## Projektstruktur

```
FabricaModelli/
‚îú‚îÄ‚îÄ whisper/                 # Whisper-spezifische Implementierungen
‚îÇ   ‚îú‚îÄ‚îÄ train_german_model.py
‚îÇ   ‚îú‚îÄ‚îÄ convert_model.py
‚îÇ   ‚îú‚îÄ‚îÄ convert_to_faster.py
‚îÇ   ‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ model_config.json
‚îÇ   ‚îî‚îÄ‚îÄ docs/
‚îÇ       ‚îú‚îÄ‚îÄ training.md
‚îÇ       ‚îî‚îÄ‚îÄ conversion.md
‚îú‚îÄ‚îÄ training/
‚îÇ   ‚îú‚îÄ‚îÄ data/              # Dataset und Cache
‚îÇ   ‚îú‚îÄ‚îÄ models/            # Trainierte Modelle
‚îÇ   ‚îî‚îÄ‚îÄ logs/             # Trainings-Logs
‚îú‚îÄ‚îÄ shared/                # Gemeinsam genutzte Funktionen
‚îÇ   ‚îú‚îÄ‚îÄ logging_utils.py
‚îÇ   ‚îî‚îÄ‚îÄ gpu_utils.py
‚îú‚îÄ‚îÄ .env                  # Lokale Umgebungsvariablen
‚îú‚îÄ‚îÄ .env.template         # Vorlage f√ºr Umgebungsvariablen
‚îú‚îÄ‚îÄ requirements.txt      # Projekt-Abh√§ngigkeiten
‚îî‚îÄ‚îÄ README.md
```

## System-Anforderungen

### Minimale Anforderungen
- NVIDIA GPU mit 16GB VRAM
- CUDA >= 11.8
- 32GB RAM
- 3TB freier Speicherplatz
- Python 3.12

### Empfohlene Hardware
- 2x NVIDIA GPU mit je 16GB VRAM
- 64GB RAM
- 4TB freier Speicherplatz (SSD/RAID)
- 8+ CPU Kerne

## üíæ Speicheranforderungen

Das Whisper-Training hat erhebliche Speicheranforderungen:

### Shared Storage (f√ºr alle Worker)
- 271 Arrow-Dateien √ó 506 MB ‚âà 137 GB
- 273 Parquet-Dateien √ó 493 MB ‚âà 135 GB
- Gesamt: ~272 GB gemeinsam genutzter Speicher

### Worker Cache
- 10 parallele Worker
- Jeder Worker: Cache w√§chst auf bis zu ~270 GB
- Gesamt Worker Cache: ~2.7 TB

### Gesamtsystem
- Shared Storage: ~272 GB
- Worker Caches: ~2.7 TB
- Spitzenlast: >3 TB w√§hrend der Verarbeitung

Details zum Cache-Management finden Sie in der [Whisper README](whisper/README.md#cache-management).

## Installation

### 1. Umgebungsvariablen einrichten

1. Kopieren Sie `.env.template` zu `.env`:
   ```bash
   cp .env.template .env
   ```

2. Passen Sie die Pfade in `.env` an Ihr System an:
   ```bash
   # Beispiel f√ºr die .env
   BASE_DIR=/pfad/zu/FabricaModelli
   DATA_DIR=${BASE_DIR}/training/data
   MODEL_DIR=${BASE_DIR}/training/models
   LOG_DIR=${BASE_DIR}/training/logs
   CONFIG_DIR=${BASE_DIR}/whisper
   ```

Die Umgebungsvariablen werden von allen Skripten verwendet, um die korrekten Pfade zu finden:
- `BASE_DIR`: Hauptverzeichnis des Projekts
- `DATA_DIR`: Speicherort f√ºr Trainingsdaten
- `MODEL_DIR`: Speicherort f√ºr trainierte Modelle
- `LOG_DIR`: Verzeichnis f√ºr Logs
- `CONFIG_DIR`: Verzeichnis f√ºr Whisper-Skripte und Konfiguration

### 2. Python-Umgebung einrichten

1. Erstellen Sie eine neue virtuelle Umgebung:
   ```bash
   python3 -m venv venv
   source venv/bin/activate
   ```

2. Installieren Sie die Abh√§ngigkeiten:
   ```bash
   pip install --upgrade pip
   pip install -r requirements.txt
   ```

### 3. Modellspezifische Installation

Die weitere Installation ist modellspezifisch. Bitte folgen Sie den Anleitungen in der jeweiligen Dokumentation:

## Lizenz

Dieses Projekt ist unter der [GPL-3.0 Lizenz](LICENSE) lizenziert.

## Beitragen

Beitr√§ge sind willkommen! Bitte erstellen Sie einen Issue oder Pull Request. Beachten Sie jedoch den Wartungshinweis am Anfang dieser README.
